# **Leveraging Large Language Models for Cloud System Design Documentation**

The increasing complexity of modern cloud-based systems necessitates thorough and well-maintained design documentation to ensure effective development, deployment, and operation. Creating this documentation can be a time-consuming and resource-intensive task. Large Language Models (LLMs) present a potential avenue for streamlining the generation of these critical documents, offering the promise of increased efficiency and reduced effort. This report aims to provide a comprehensive guide and a detailed prompt template to enable technical leaders and senior software engineers to effectively utilize LLMs for generating high-quality design documents for cloud-based systems. It will explore the principles of prompt engineering, analyze best practices for this specific application, present a comprehensive prompt template covering essential aspects of cloud system design, discuss common pitfalls associated with using LLMs for technical documentation, and offer guidance on refining the prompting process for optimal results.

**II. The Art and Science of Prompt Engineering for Technical Documentation**

Crafting effective prompts is fundamental to harnessing the power of LLMs for technical documentation. The principles of prompt engineering serve as the foundation for guiding these models to produce accurate, relevant, and well-structured outputs.

* **Clarity and Specificity:** Providing clear and unambiguous instructions is paramount when interacting with LLMs.1 Vague prompts often lead to generic or irrelevant responses, as the LLM lacks the necessary direction to focus its generation. Specificity acts as a precise roadmap, guiding the model towards the desired content and format.1 For instance, instead of a broad instruction like "Write a design document," a more effective prompt would specify the system's purpose, such as "Generate a design document for a customer management system hosted on AWS, focusing on scalability and security." This level of detail significantly narrows the scope and helps the LLM understand the intended output.1  
* **Context and Background Information:** Supplying relevant context enables the LLM to generate more accurate and tailored responses.1 LLMs operate based on the information provided within the prompt. Insufficient context can result in the model making assumptions or producing irrelevant information.1 If an LLM is asked to describe the architecture of a system without understanding its core functionality or the environment in which it will operate (e.g., an e-commerce platform versus a data analytics pipeline), it will struggle to provide a pertinent design. Background details about the system's domain, objectives, and any existing constraints are crucial for the LLM to understand the 'why' behind the design requirements and generate a more meaningful document.1  
* **Role Definition and Persona:** Assigning a specific role to the LLM can significantly influence its tone and the expertise it brings to the generated content.1 Instructing the LLM to act as a "senior solutions architect" or a "cloud security expert" can lead to more knowledgeable and relevant output.1 By adopting a particular persona, the LLM can tap into its training data associated with that role, resulting in responses that align with the expected expertise and perspective. For example, when prompted as a "senior solutions architect," the LLM is more likely to incorporate standard architectural patterns and consider aspects like scalability, resilience, and cost-effectiveness, drawing upon its training data related to this professional domain.1  
* **Output Format and Structure:** Clearly specifying the desired output format and structure is essential for ensuring the generated design document is well-organized and easy to read.8 Guiding the LLM on the desired format, such as requesting the output in Markdown format with specific headings for sections like "System Overview," "Architecture," and "Security," ensures the model organizes the information logically, mirroring a standard design document structure.8 Furthermore, specifying the use of bullet points or numbered lists can enhance readability and make the document easier to navigate.10  
* **Use of Examples (Few-Shot Prompting):** Providing a few examples of the desired output, known as few-shot prompting, can be a powerful technique to guide the LLM.9 Examples can clarify the expected style, level of detail, and content for each section of the design document.9 By showing the LLM what a good design document looks like, even in a simplified form, it can better understand the desired outcome. For instance, providing a short example of a "System Overview" section that includes key elements like the system name, its primary purpose, and the intended target audience can help the LLM understand the expected level of detail and the type of information to include in that section for the specific system being documented.  
* **Iterative Refinement:** Prompt engineering is often an iterative process, requiring adjustments based on the LLM's initial responses.1 The first attempt at crafting a prompt might not yield the perfect result. Reviewing the LLM's output and refining the prompt based on the generated content is a key step in achieving the desired quality and level of detail.1 LLMs are powerful but might misinterpret certain aspects of the prompt or not provide the depth of information required. Iteration allows for fine-tuning the instructions to address any shortcomings in the initial output. For example, if the LLM's initial response for the "Security" section is too high-level, the prompt can be refined to ask for specific details on authentication mechanisms or data encryption methods.

**III. Deconstructing Best Practices for LLM-Generated Cloud System Design Documents**

Analyzing existing research on prompt engineering for technical documentation, particularly in the context of cloud systems, reveals several common elements and effective phrasing. These insights provide a foundation for developing robust prompting strategies.

Many examples emphasize focusing prompts on generating specific sections of technical documents, such as software requirements specifications or API documentation.4 This suggests that prompting for individual sections of a cloud system design document might be more effective than attempting to generate the entire document with a single prompt. Breaking down the task into smaller, more manageable parts can improve the quality and focus of the LLM's output for each section, allowing for more targeted instructions and better control over the content. For instance, instead of a single prompt like "Write a design document for a cloud system," prompting for "Write the 'Security' section of the design document for a cloud-based patient record system, detailing access control and data encryption methods" is likely to yield a more focused and detailed response.

The importance of providing ample contextual information is consistently highlighted across the research.1 The more information the LLM has about the system, including its purpose, target audience, specific functional and non-functional requirements, and any relevant constraints, the better it can tailor the design document to the specific needs. Without sufficient context, LLMs may make incorrect assumptions or generate irrelevant information. For example, when prompting for the "Scalability" section, providing information about the expected user growth, peak load, and performance targets will enable the LLM to suggest more relevant and appropriate scaling strategies.

Specifying architectural styles and patterns within the prompt can also be beneficial.7 Guiding the LLM towards established architectural patterns, such as microservices, serverless, or a specific design pattern like CQRS, can ensure the generated design is based on sound principles and industry best practices. If the system requires high availability and fault tolerance, the prompt can specify the use of a microservices architecture with a load balancer, guiding the LLM to incorporate these essential elements into the design.

Effective prompts often explicitly request details on key aspects of a cloud system, including its components, data flow, security measures, scalability strategies, and deployment considerations.8 These are fundamental elements of any comprehensive cloud system design document, and the prompt should act as a checklist to ensure the LLM addresses each critical area. To ensure the "Components" section is thorough, the prompt should explicitly ask for the name, responsibilities, functionality, and interactions of each key component within the system's architecture.

Leveraging role-playing by instructing the LLM to act as a software architect, technical lead, or cloud security expert can also enhance the quality of the generated documentation.2 This technique helps the LLM adopt a more professional and knowledgeable tone, potentially incorporating relevant industry best practices and considerations that might be missed with a more generic prompt. Prompting the LLM to "Act as a senior cloud security architect and describe the security measures for this system" will likely result in a more comprehensive and expert-level response compared to a less specific request.

Finally, while not directly part of the technical architecture, prompts can also include questions about non-functional requirements such as potential risks, challenges, timelines, and budget considerations.12 A comprehensive design document often acknowledges these broader project aspects. While prompting for the technical details of the database design, it can also be valuable to ask about potential risks associated with the chosen database technology and strategies to mitigate those risks.

Based on these findings, several key considerations and recommended approaches emerge for effectively using LLMs to generate cloud system design documentation. Starting with clear objectives and precisely defining the scope and goals of the design document is crucial.1 Using clear and concise language in the prompts, avoiding jargon or ambiguous terms, minimizes the chances of the LLM misinterpreting the instructions.1 Being prepared to iterate on the prompts and refine them based on the LLM's output is essential for achieving the desired level of detail and accuracy.1 Employing structured prompts, organized into logical sections that mirror the typical structure of a design document, helps the LLM understand the different components and address them systematically.8 Considering the use of few-shot examples can provide concrete illustrations for the LLM and improve the quality and format of the generated content.9 Finally, it is imperative to always validate and verify the information generated by the LLM for accuracy and completeness, as human oversight remains crucial for ensuring the reliability of the design document.18

**IV. A Comprehensive Prompt Template for Cloud System Design**

Synthesizing the best practices and insights discussed above, a comprehensive prompt template for generating a cloud-based system design document using an LLM can be structured as follows:

**Please act as a Senior Solutions Architect with expertise in cloud-based system design. Your task is to generate a detailed design document for a system. Please ensure the document covers the following sections with the specified level of detail:**

* **System Overview:**  
  * **Purpose and Goals:** Clearly describe the main objectives and intended functionality of the cloud-based system. What problems will it solve, and what are its primary goals?  
  * **Target Audience:** Specify who will be the primary users or stakeholders of this system. What are their technical proficiencies and needs?  
  * **High-Level Requirements:** Outline the key functional requirements (what the system should do) and non-functional requirements (e.g., performance, availability, security expectations). 12  
* **Architecture:**  
  * **Overall Architecture Diagram (Textual Representation):** Describe the high-level architectural components of the system and their interactions. Specify the different layers or tiers and how they communicate. If possible, provide a textual representation of a high-level diagram using standard architectural notations or clear descriptions. 12  
  * **Architectural Style:** Specify the chosen architectural style (e.g., microservices, monolithic, serverless, event-driven) and provide a clear rationale for this selection based on the system's requirements. 12  
  * **Key Architectural Decisions:** Highlight the most significant architectural decisions made during the design process and provide justifications for these choices, considering factors like scalability, maintainability, cost, and security.  
* **Components:**  
  * For each major component identified in the architecture (e.g., web server, application server, database, message queue, caching layer):  
    * **Name and Description:** Provide a detailed description of the component's responsibilities and key functionalities. 8  
    * **Technology Stack:** Specify the primary technologies, programming languages, frameworks, and libraries that will be used for this component.  
    * **APIs and Interfaces:** Describe any APIs or interfaces this component will expose or consume, including the communication protocols and data formats. 14  
* **Data Flow:**  
  * Describe the end-to-end flow of data through the system for key use cases. Explain how data is ingested, processed, transformed, and stored. 8  
  * **Data Model (High-Level):** Provide a high-level overview of the system's data model, including the key entities, their attributes, and the relationships between them. 8  
  * **Data Storage Solutions:** Specify the types of databases and storage services that will be used (e.g., relational database, NoSQL database, object storage) and provide a rationale for their selection based on data characteristics and access patterns. 12  
* **Security:**  
  * **Security Requirements:** Outline the key security requirements for the system, including authentication, authorization, data confidentiality, integrity, and availability. Mention any relevant compliance standards or regulatory requirements. 25  
  * **Security Measures:** Describe the security measures that will be implemented at different layers of the system (e.g., network security, application security, data security, infrastructure security). Specify the use of any cloud-specific security services. 5  
  * **Authentication and Authorization:** Explain the mechanisms for user authentication (verifying identity) and authorization (controlling access to resources). 5  
  * **Data Encryption:** Specify how sensitive data will be encrypted both at rest (when stored) and in transit (when transmitted over the network). 5  
  * **Vulnerability Management:** Describe the strategy for identifying, assessing, and mitigating security vulnerabilities in the system. 25  
* **Scalability:**  
  * **Scalability Requirements:** Define the expected scalability needs of the system, including anticipated user growth, peak loads, and performance targets. 12  
  * **Scalability Strategies:** Describe the strategies that will be employed to ensure the system can handle increasing load and maintain performance (e.g., auto-scaling of compute resources, load balancing, database scaling techniques). 8  
  * **Performance Considerations:** Outline any specific performance requirements (e.g., response times, throughput) and how the design will address these. 5  
* **Deployment:**  
  * **Deployment Model:** Specify the chosen deployment model (e.g., public cloud, private cloud, hybrid cloud). 12  
  * **Deployment Process (High-Level):** Describe the high-level steps involved in deploying the system to the target environment. 12  
  * **Infrastructure as Code (IaC):** Indicate whether Infrastructure as Code (IaC) tools (e.g., Terraform, CloudFormation) will be used for provisioning and managing the cloud infrastructure.  
* **Monitoring and Logging:**  
  * **Monitoring Requirements:** Define the key metrics that will be monitored to ensure the health and performance of the system (e.g., CPU utilization, memory usage, network latency, error rates). 12  
  * **Monitoring Tools and Strategies:** Specify the tools and strategies that will be used for monitoring the system and generating alerts for critical issues. 12  
  * **Logging Strategy:** Describe how logs will be collected, stored, and analyzed for troubleshooting, auditing, and gaining insights into system behavior. 12  
* **Disaster Recovery and Business Continuity:**  
  * **Recovery Objectives (RTO/RPO):** Define the target Recovery Time Objective (RTO) and Recovery Point Objective (RPO) for the system. 8  
  * **Disaster Recovery Plan (High-Level):** Outline the high-level plan for recovering the system and its data in the event of a disaster or significant outage. 8  
  * **Backup and Restore Strategy:** Describe the approach for backing up critical data and restoring it in case of data loss. 8  
* **Cost Considerations (High-Level):**  
  * Provide a high-level estimate of the anticipated costs associated with the cloud infrastructure and services required to run the system. 12  
  * Outline any initial cost optimization strategies that will be considered during the implementation phase.

**Please ensure the generated document is well-structured, uses clear and concise language, and maintains a formal and technical tone consistent with standard engineering documentation.**

| Section | Description |
| :---- | :---- |
| System Overview | Purpose, target audience, high-level requirements. |
| Architecture | Overall diagram, architectural style, key decisions and justifications. |
| Components | Detailed descriptions, technology stack, APIs and interfaces for each component. |
| Data Flow | How data moves through the system, data model, data storage solutions. |
| Security | Security requirements, measures, authentication, authorization, encryption, vulnerability management. |
| Scalability | Scalability requirements, strategies (auto-scaling, load balancing), performance considerations. |
| Deployment | Deployment model, process, use of Infrastructure as Code. |
| Monitoring and Logging | Key metrics, tools and strategies for monitoring, logging strategy. |
| Disaster Recovery | Recovery objectives (RTO/RPO), disaster recovery plan, backup and restore strategy. |
| Cost Considerations | Estimated costs, cost optimization strategies. |

**V. Navigating the Challenges: Addressing Common Pitfalls of LLM-Generated Technical Documentation**

While LLMs offer significant potential for generating technical documentation, it is important to be aware of their limitations and common pitfalls to ensure the quality and accuracy of the output.

One significant challenge is the potential for inaccuracies and hallucinations, where LLMs may generate factually incorrect information.19 To mitigate this, the prompt template emphasizes the need for the LLM to base its responses on well-established knowledge and encourages the citation of sources where possible. Furthermore, it is crucial to always subject the LLM-generated content to thorough human review and verification by subject matter experts. The principle of "trust but verify" is paramount when using LLMs for technical documentation, as their knowledge, while vast, is not always flawless or up-to-date.

LLMs may also struggle with complex reasoning or nuanced technical concepts, sometimes lacking a deep understanding of the subject matter.19 To address this, the prompt template encourages breaking down complex topics into smaller, more manageable parts. Asking the LLM to explain its reasoning step by step, employing chain-of-thought prompting techniques, can also help guide the model through a more logical and in-depth analysis. This approach encourages the LLM to engage in a more thorough reasoning process rather than just providing surface-level information retrieval.

Although less of a concern for purely technical documentation, LLMs can sometimes reflect biases present in their training data.19 While the prompt template instructs the LLM to maintain a neutral and objective tone, users should still be mindful of potentially biased language in the generated output. Ensuring neutrality and objectivity in technical documentation is important for clarity, accuracy, and professionalism.

Inconsistency in style, tone, and terminology is another potential pitfall.18 To mitigate this, the prompt template explicitly requests a formal and technical writing style consistent with standard engineering documentation. Providing examples of existing documentation to the LLM, if available, can further help it emulate the desired style. Utilizing system instructions within the prompting framework can also aid in enforcing consistency throughout the generated document.

LLMs primarily excel at generating text and may encounter difficulties with creating or accurately describing complex visuals and diagrams.29 The prompt template addresses this by focusing the LLM on providing detailed textual descriptions of the system architecture and its components. If diagrams are essential, the textual output from the LLM can serve as a basis for creating visualizations using dedicated diagramming tools. While some LLMs possess rudimentary diagram generation capabilities, specifying the desired format in the prompt may yield limited results for complex architectural diagrams.

A significant risk associated with using LLMs is the potential for over-reliance on their output without applying critical thinking.20 The introduction to the prompt template should include a clear disclaimer emphasizing that the LLM's output should be treated as a starting point and requires thorough review and validation by human experts. LLMs are valuable tools to assist in the documentation process but should not be considered a replacement for human expertise and critical judgment.

Finally, maintaining the currency of technical documentation is an ongoing challenge.16 The prompt template can be adapted for updating specific sections of an existing design document based on changes in system requirements or functionality, rather than requiring the LLM to regenerate the entire document. Regularly prompting the LLM with updated information relevant to a particular section can help keep the design documentation up-to-date with the evolving cloud system.

**VI. Refining Your Approach: Iteration and Best Practices for Optimal Results**

The effectiveness of the prompt template can be further enhanced through an iterative refinement process. Testing the template with different LLM models and carefully reviewing their outputs is crucial for identifying areas for improvement.10 It is recommended to start by focusing on a specific section of the design document, iteratively adjusting the prompt for that section until satisfactory results are achieved before moving on to other parts of the template.

Experimenting with different prompting techniques, such as zero-shot prompting (providing the prompt without examples), few-shot prompting (including a few examples of the desired output), and chain-of-thought prompting (guiding the LLM through a step-by-step reasoning process), can reveal which approach yields the best results for different sections of the design document.10 Providing specific feedback to the LLM on its generated output, highlighting areas that need more detail, clarification, or correction, can also guide further refinements of the prompt. Once effective prompts for different sections are developed, it is advisable to save and version these prompts for future use, ensuring consistency and efficiency in generating design documentation for similar cloud systems.17

**VII. Conclusion**

Leveraging Large Language Models for generating cloud system design documents, when guided by well-engineered prompts, offers numerous potential benefits, including increased efficiency and reduced effort in creating this essential documentation. The key to success lies in crafting prompts with clarity, specificity, and sufficient context, while also considering the role and desired output format. The iterative nature of prompt engineering allows for continuous refinement, leading to higher quality and more accurate results. However, it is crucial to acknowledge the inherent limitations of LLMs, particularly the potential for inaccuracies and the lack of deep understanding. Therefore, human expertise and thorough review remain indispensable for ensuring the reliability and completeness of the final design document. As AI technology continues to evolve, LLMs will likely play an increasingly significant role in streamlining technical documentation processes, acting as valuable tools to assist technical professionals in effectively communicating complex system designs.

#### **引用文献**

1. Beginner's Guide to Engineering Prompts for LLMs \- Oracle Blogs, 5月 2, 2025にアクセス、 [https://blogs.oracle.com/ai-and-datascience/post/beginners-guide-engineering-prompts-llm](https://blogs.oracle.com/ai-and-datascience/post/beginners-guide-engineering-prompts-llm)  
2. Prompt Engineering Guide: Tutorial, best practises, examples, 5月 2, 2025にアクセス、 [https://www.kopp-online-marketing.com/prompt-engineering-guide-tutorial-best-practises-examples](https://www.kopp-online-marketing.com/prompt-engineering-guide-tutorial-best-practises-examples)  
3. Prompt Engineering for AI Guide | Google Cloud, 5月 2, 2025にアクセス、 [https://cloud.google.com/discover/what-is-prompt-engineering](https://cloud.google.com/discover/what-is-prompt-engineering)  
4. Prompts For Technical Documentation: Enhance Your Writing Skills \- PromptsTY, 5月 2, 2025にアクセス、 [https://promptsty.com/prompts-for-technical-documentation/](https://promptsty.com/prompts-for-technical-documentation/)  
5. How to write good prompts for generating code from LLMs \- GitHub, 5月 2, 2025にアクセス、 [https://github.com/potpie-ai/potpie/wiki/How-to-write-good-prompts-for-generating-code-from-LLMs](https://github.com/potpie-ai/potpie/wiki/How-to-write-good-prompts-for-generating-code-from-LLMs)  
6. Examples of Prompts | Prompt Engineering Guide, 5月 2, 2025にアクセス、 [https://www.promptingguide.ai/introduction/examples](https://www.promptingguide.ai/introduction/examples)  
7. Software Architect Prompt \- DocsBot AI, 5月 2, 2025にアクセス、 [https://docsbot.ai/prompts/technical/software-architect-prompt](https://docsbot.ai/prompts/technical/software-architect-prompt)  
8. Best ChatGPT Prompt to System Architecture Generator \- Writing, 5月 2, 2025にアクセス、 [https://www.godofprompt.ai/prompt?prompt=create-system-architecture-document](https://www.godofprompt.ai/prompt?prompt=create-system-architecture-document)  
9. Prompt engineering techniques and best practices: Learn by doing with Anthropic's Claude 3 on Amazon Bedrock | AWS Machine Learning Blog, 5月 2, 2025にアクセス、 [https://aws.amazon.com/blogs/machine-learning/prompt-engineering-techniques-and-best-practices-learn-by-doing-with-anthropics-claude-3-on-amazon-bedrock/](https://aws.amazon.com/blogs/machine-learning/prompt-engineering-techniques-and-best-practices-learn-by-doing-with-anthropics-claude-3-on-amazon-bedrock/)  
10. Sample foundation model prompts for common tasks | IBM watsonx \- IBM Cloud Pak for Data, 5月 2, 2025にアクセス、 [https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-prompt-samples.html?context=wx\&pos=10](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-prompt-samples.html?context=wx&pos=10)  
11. Introduction to prompting | Generative AI on Vertex AI | Google Cloud, 5月 2, 2025にアクセス、 [https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/introduction-prompt-design)  
12. 30 Useful ChatGPT Prompts for Software ... \- KMS Technology, 5月 2, 2025にアクセス、 [https://kms-technology.com/emerging-technologies/ai/30-best-chatgpt-prompts-for-software-engineers.html](https://kms-technology.com/emerging-technologies/ai/30-best-chatgpt-prompts-for-software-engineers.html)  
13. AI Prompts: The Future of Technical Writing \- Document360, 5月 2, 2025にアクセス、 [https://document360.com/blog/ai-prompts-for-technical-writing/](https://document360.com/blog/ai-prompts-for-technical-writing/)  
14. Prompt patterns for LLMs that help you design better software \- Chuniversiteit.nl, 5月 2, 2025にアクセス、 [https://chuniversiteit.nl/papers/prompt-patterns-for-software-design](https://chuniversiteit.nl/papers/prompt-patterns-for-software-design)  
15. Collection of ChatGPT (or other LLM) priming prompts for software architecture \- GitHub, 5月 2, 2025にアクセス、 [https://github.com/mikaelvesavuori/chatgpt-architecture-coach](https://github.com/mikaelvesavuori/chatgpt-architecture-coach)  
16. 12 common pitfalls in LLM agent integration (and how to avoid them), 5月 2, 2025にアクセス、 [https://www.barrage.net/blog/technology/12-pitfalls-in-llm-integration-and-how-to-avoid-them](https://www.barrage.net/blog/technology/12-pitfalls-in-llm-integration-and-how-to-avoid-them)  
17. 5 Patterns for Scalable Prompt Design \- Latitude.so, 5月 2, 2025にアクセス、 [https://latitude.so/blog/5-patterns-for-scalable-prompt-design/](https://latitude.so/blog/5-patterns-for-scalable-prompt-design/)  
18. From tedious to seamless: How LLMs are revolutionizing technical documentation? \- Confiz, 5月 2, 2025にアクセス、 [https://www.confiz.com/blog/from-tedious-to-seamless-how-llms-are-revolutionizing-technical-documentation/](https://www.confiz.com/blog/from-tedious-to-seamless-how-llms-are-revolutionizing-technical-documentation/)  
19. Limitations of LLMs: Bias, Hallucinations, and More \- Learn Prompting, 5月 2, 2025にアクセス、 [https://learnprompting.org/docs/basics/pitfalls](https://learnprompting.org/docs/basics/pitfalls)  
20. 10 Benefits and 10 Challenges of Applying Large Language Models to DoD Software Acquisition \- SEI Blog, 5月 2, 2025にアクセス、 [https://insights.sei.cmu.edu/blog/10-benefits-and-10-challenges-of-applying-large-language-models-to-dod-software-acquisition/](https://insights.sei.cmu.edu/blog/10-benefits-and-10-challenges-of-applying-large-language-models-to-dod-software-acquisition/)  
21. AI Architecture Diagram Generator \- Eraser IO, 5月 2, 2025にアクセス、 [https://www.eraser.io/ai/architecture-diagram-generator](https://www.eraser.io/ai/architecture-diagram-generator)  
22. Generative AI prompt samples \- Google Cloud, 5月 2, 2025にアクセス、 [https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery](https://cloud.google.com/vertex-ai/generative-ai/docs/prompt-gallery)  
23. Emerging Architectures for LLM Applications | Andreessen Horowitz, 5月 2, 2025にアクセス、 [https://a16z.com/emerging-architectures-for-llm-applications/](https://a16z.com/emerging-architectures-for-llm-applications/)  
24. Writing Prompts in deepset AI Platform, 5月 2, 2025にアクセス、 [https://docs.cloud.deepset.ai/docs/write-prompts-in-deepset-cloud](https://docs.cloud.deepset.ai/docs/write-prompts-in-deepset-cloud)  
25. Top 10 LLM Prompts Every Cybersecurity Professional Should ..., 5月 2, 2025にアクセス、 [https://www.kiledjian.com/main/2024/9/24/top-10-llm-prompts-every-cybersecurity-professional-should-know-to-boost-security](https://www.kiledjian.com/main/2024/9/24/top-10-llm-prompts-every-cybersecurity-professional-should-know-to-boost-security)  
26. AI Prompt and Inference Pipeline Threats \- Pangea.Cloud, 5月 2, 2025にアクセス、 [https://pangea.cloud/securebydesign/aiapp-threats-inference/](https://pangea.cloud/securebydesign/aiapp-threats-inference/)  
27. why can't we have LLMs writing documentation? : r/AskProgramming \- Reddit, 5月 2, 2025にアクセス、 [https://www.reddit.com/r/AskProgramming/comments/1j1n51j/why\_cant\_we\_have\_llms\_writing\_documentation/](https://www.reddit.com/r/AskProgramming/comments/1j1n51j/why_cant_we_have_llms_writing_documentation/)  
28. 8 Challenges Of Building Your Own Large Language Model \- Labellerr, 5月 2, 2025にアクセス、 [https://www.labellerr.com/blog/challenges-in-development-of-llms/](https://www.labellerr.com/blog/challenges-in-development-of-llms/)  
29. What is the best LLM for generating architecture diagram : r/LocalLLaMA \- Reddit, 5月 2, 2025にアクセス、 [https://www.reddit.com/r/LocalLLaMA/comments/1hiqfl1/what\_is\_the\_best\_llm\_for\_generating\_architecture/](https://www.reddit.com/r/LocalLLaMA/comments/1hiqfl1/what_is_the_best_llm_for_generating_architecture/)  
30. Advanced Prompt Engineering Techniques \- Mercity AI, 5月 2, 2025にアクセス、 [https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques](https://www.mercity.ai/blog-post/advanced-prompt-engineering-techniques)